
<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ji Qi</title>
  <meta name="author" content="Ji Qi">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="UTF-8">
  <meta http-equiv="Content-type" content="text/html; charset=UTF-8">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table
    style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:20%;max-width:60%">
                  <a href="images/photo.jpg"><img style="width:100%;max-width:100%" alt="profile photo"
                      src="images/photo.jpg" class="hoverZoomLink"></a>
                </td>
                <td style="padding:2.5%;width:65%;vertical-align:middle">
                  <p>
                    <name>Ji Qi 齐济</name>
                  </p>
                  <p>
                  I am a fourth-year Ph.D. student at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>, advised by <a href="https://keg.cs.tsinghua.edu.cn/persons/xubin/">Prof. Bin Xu</a> and <a href="https://keg.cs.tsinghua.edu.cn/persons/ljz/">Prof. Juanzi Li</a>. Currently, I'm a visiting student at <a href="https://www.nextcenter.org/">NExT++ Lab</a> in <a href="https://nus.edu.sg/">National University of Singapore</a>, advised by <a href="https://www.comp.nus.edu.sg/cs/people/chuats/">Prof. Tat-Seng Chua</a>.
                  </p>
                  <p>
                    <a href="mailto:qj20@mails.tsinghua.edu.cn">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=vv6bZjMAAAAJ">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/qijimrc/">Github</a>&nbsp/&nbsp
                    <a href="#SelectedPublications">Selected Publications</a>&nbsp/&nbsp
                    <a href="#Experience">Experience</a>&nbsp/&nbsp
                    <a href="#HonorsAwards">Honors & Awards</a>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr id="SelectedPublications">
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Selected Publications</heading>
                  <p>
                    My research interests lies in Multimodal Large Language Models. I am currently focused on <strong>Training Multimodal Language Models</strong> involving <strong>Long Context</strong> and <strong>Videos</strong>.
                    Here are some of my lead works:
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:10px;width:30%;vertical-align:middle">
                  <a href="images/cogcom.jpg"><img src='images/cogcom.jpg' width="100%"></a>
                </td>
                <td style="padding:20px;width:70%;vertical-align:middle">
                  <papertitle>CogCoM: Train Large Vision-Language Models Diving into Details through Chain of Manipulations.</papertitle>
                  <br>
                  <strong>Ji Qi</strong>,
                  Ming Ding, Weihan Wang, Yushi Bai, Qingsong Lv, Wenyi Hong, Bin Xu, Lei Hou, Juanzi Li, Yuxiao Dong, Jie Tang
                  <br>
                  arXiv
                  <br>
                  [<a href="https://arxiv.org/pdf/2402.04236.pdf">paper</a>]
                  [<a href="https://github.com/THUDM/CogCoM">code</a>]
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:30%;vertical-align:middle">
                  <a href="images/cogvlm.jpg"><img src='images/cogvlm.jpg' width="100%"></a>
                </td>
                <td style="padding:20px;width:70%;vertical-align:middle">
                  <papertitle>CogVLM: Visual Expert for Large Language Models</papertitle>
                  <br>
                  Weihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Hong, <strong>Ji Qi</strong>, Yan Wang, Junhui Ji, Zhuoyi Yang, Lei Zhao, Xixuan Song, Jiazheng Xu, Xu Bin, Juanzi Li, Jie Tang, Ming Ding
                  <br>
                  arXiv
                  <br>
                  [<a href="https://arxiv.org/abs/2311.03079">paper</a>]
                  [<a href="https://github.com/THUDM/CogVLM">code</a>]
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:30%;vertical-align:middle">
                  <a href="images/vidcom.jpg"><img src='images/vidcom.jpg' width="100%"></a>
                </td>
                <td style="padding:20px;width:70%;vertical-align:middle">
                  <papertitle>VidCoM: Fast Video Comprehension through Large Language Models with Multimodal Tools</papertitle>
                  <br>
                  <strong>Ji Qi</strong>,
                  Kaixuan Ji, Jifan Yu, Duokang Wang, Bin Xu, Lei Hou, Juanzi Li
                  <br>
                  arXiv
                  <br>
                  [<a href="https://arxiv.org/abs/2310.10586">paper</a>]
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:30%;vertical-align:middle">
                  <a href="images/goal.jpg"><img src='images/goal.jpg' width="100%"></a>
                </td>
                <td style="padding:20px;width:70%;vertical-align:middle">
                  <papertitle>GOAL: A Challenging Knowledge-grounded Video Captioning Benchmark for Real-time Soccer Commentary Generation</papertitle>
                  <br>
                  <strong>Ji Qi*</strong>,
                  Jifan Yu*, Teng Tu, Kunyu Gao, Yifan Xu, Xinyu Guan, Xiaozhi Wang, Bin Xu, Lei Hou, Juanzi Li, Jie Tang
                  <br>
                  CIKM 2023
                  <br>
                  [<a href="https://arxiv.org/abs/2303.14655">paper</a>]
                  [<a href="https://github.com/THU-KEG/goal">website</a>]
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:30%;vertical-align:middle">
                  <a href="images/robust.jpg"><img src='images/robust.jpg' width="100%"></a>
                </td>
                <td style="padding:20px;width:70%;vertical-align:middle">
                  <papertitle>Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction</papertitle>
                  <br>
                  <strong>Ji Qi</strong>,
                  Chuchun Zhang, Xiaozhi Wang, Kaisheng Zeng, Jifan Yu, Jinxin Liu, Jiuding Sun, Yuxiang Chen, Lei How, Juanzi Li, Bin Xu
                  <br>
                  EMNLP 2023 (<span style="color:#C70039">**Outstanding Paper Award**</span>)
                  <br>
                  [<a href="https://arxiv.org/abs/2305.13981">paper</a>]
                  [<a href="https://github.com/qijimrc/ROBUST">code</a>]
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:10px;width:30%;vertical-align:middle">
                  <a href="images/robustoie.jpg"><img src='images/robustoie.jpg' width="100%"></a>
                </td>
                <td style="padding:20px;width:70%;vertical-align:middle">
                  <papertitle>Syntactically Robust Training on Partially-Observed Data for Open Information Extraction</papertitle>
                  <br>
                  <strong>Ji Qi</strong>,
                  Yuxiang Chen, Lei Hou, Juanzi Li, Bin Xu
                  <br>
                  EMNLP 2022
                  <br>
                  [<a href="https://arxiv.org/abs/2301.06841">paper</a>]
                  [<a href="https://github.com/qijimrc/RobustOIE">code</a>]
                  <p></p>
                </td>
              </tr>
            </tbody>
          </table>

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
              <tr id="Experience">
                <td>
                  <heading>Experience</heading>
                </td>
              </tr>
            </tbody>
          </table>
          <table width="100%" align="center" border="0" cellpadding="10">
            <tbody>
              <tr>
                <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img
                    src="images/thu.png" , width="80%"></td>
                <td width="80%" valign="center">
                  <b>Tsinghua University</b>
                  <br> 2020.09 - Present <br>
                  <br> <b>Ph.D student in Computer Science and Technology</b>
                  <br> Advisor: <a href="https://keg.cs.tsinghua.edu.cn/persons/xubin/">Prof. Bin Xu</a> and <a href="http://keg.cs.tsinghua.edu.cn/persons/ljz/">Prof. Juanzi Li</a>
                </td>
              </tr>
              <tr>
                <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img
                    src="images/nus.jpg" , width="80%"></td>
                <td width="100%" valign="center">
                  <b>National University of Singapore</b>
                  <br> 2024.04-2024.10
                  <br>
                  <br> <b>Visiting Research Student</b>
                  <br> Advisor: <a href="https://www.comp.nus.edu.sg/cs/people/chuats/">Prof. Tat-Seng Chua</a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr id="HonorsAwards">
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Honors & Awards</heading>
                  <ul>
                    <li>Outstanding Paper Award from EMNLP 2023, 2023</li>
                    <li>Dengfeng Scholarship from Tsinghua University, 2023</li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:0px">
                  <br>
                  <p style="text-align:right;font-size:small;">
                    Template adapted from <a href="https://jonbarron.info/">Jon Barron</a>.
                    <script type='text/javascript' id='clustrmaps'
                      src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=200&t=n&d=FYhBoxLDEaFAxdfRzk5TuchYOBGrnSa98Ky59EkEEpY'>
                      </script>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>
        </td>
      </tr>
  </table>
</body>

</html>
